import os
import cv2
import numpy as np
import tempfile
import subprocess
import streamlit as st
import mediapipe as mp
from mediapipe.framework.formats import landmark_pb2

# ---- ãƒ­ã‚°æŠ‘åˆ¶ï¼ˆä»»æ„ï¼‰----
os.environ["GLOG_minloglevel"] = "2"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# ------------------------
# ffmpeg ã§å¸¸æ™‚æ­£è¦åŒ–ï¼ˆH.264/MP4ãƒ»720pãƒ»30fpsãƒ»éŸ³å£°ãªã—ï¼‰
# ------------------------
def ffmpeg_normalize(input_path: str) -> str:
    out_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
    cmd = [
        "ffmpeg", "-y", "-i", input_path,
        "-vf", "scale='min(1280,iw)':-2", "-r", "30",
        "-c:v", "libx264", "-pix_fmt", "yuv420p",
        "-preset", "veryfast", "-crf", "23",
        "-an",
        out_path
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)
    return out_path

# ------------------------
# å‹•ç”»ãƒ¡ã‚¿æƒ…å ±
# ------------------------
def get_video_info(path):
    cap = cv2.VideoCapture(path)
    if not cap.isOpened():
        return 0, 0, 0, 0
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0
    fps = float(cap.get(cv2.CAP_PROP_FPS)) or 30.0
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 0
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 0
    cap.release()
    return total, fps, w, h

# ------------------------
# ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’1æšã ã‘èª­ã¿è¾¼ã‚€ï¼ˆã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ï¼‰
# ------------------------
def read_frame(path: str, idx: int, max_h=640):
    cap = cv2.VideoCapture(path)
    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
    ok, frame = cap.read()
    cap.release()
    if not ok or frame is None:
        return None
    h, w = frame.shape[:2]
    if h > max_h:
        nh = max_h
        nw = int(w * (max_h / h))
        frame = cv2.resize(frame, (nw, nh), interpolation=cv2.INTER_AREA)
    return frame

# ------------------------
# Pose æ¨å®šï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# ------------------------
@st.cache_resource
def get_pose(model_complexity: int):
    return mp_pose.Pose(
        static_image_mode=False,
        model_complexity=model_complexity,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )

@st.cache_data
def detect_landmarks(path, idx, model_complexity):
    pose = get_pose(model_complexity)
    frame = read_frame(path, idx)
    if frame is None:
        return None
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(rgb)
    lm = getattr(results, "pose_landmarks", None)
    if lm is None:
        return None
    arr = np.zeros((33, 4), np.float32)
    for i, p in enumerate(lm.landmark):
        arr[i] = [p.x, p.y, p.z, p.visibility]
    return arr

def draw_skeleton(frame, arr, color=(255,0,0)):
    if arr is None:
        return frame
    lm_list = landmark_pb2.NormalizedLandmarkList(
        landmark=[
            landmark_pb2.NormalizedLandmark(x=float(x), y=float(y), z=float(z), visibility=float(v))
            for (x, y, z, v) in arr
        ]
    )
    spec = mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2)
    mp_drawing.draw_landmarks(frame, lm_list, mp_pose.POSE_CONNECTIONS, spec, spec)
    return frame

# ------------------------
# UI
# ------------------------
st.set_page_config(layout="wide", page_title="ãƒãƒ¬ã‚¨ãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒAI")
st.title("ğŸ’ƒ ãƒãƒ¬ã‚¨ãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒAI")

st.markdown("""
### ã”åˆ©ç”¨æ–¹æ³•
1. æ¯”è¼ƒã—ãŸã„å‹•ç”»ã‚’ **2æœ¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**ï¼ˆé †ã« é’ â†’ èµ¤ï¼‰
2. **è§£æã‚’é–‹å§‹** ã‚’æŠ¼ã™ã¨ã€AIãŒè‡ªå‹•ã§éª¨æ ¼ã‚’æ¤œå‡ºã—ã¦æ¯”è¼ƒã—ã¾ã™ã€‚

> â„¹ï¸ å¤‰æ›ã‚„è¨­å®šã¯ä¸è¦ã§ã™ï¼ˆã‚¢ãƒ—ãƒªå´ã§ **H.264/MP4ãƒ»720pãƒ»30fps** ã«è‡ªå‹•èª¿æ•´ï¼‰ã€‚  
> ğŸ¯ æœ€ã‚‚æ­£ç¢ºã«è§£æã§ãã‚‹ã®ã¯ **1äººã®å…¨èº«ãŒæ˜ ã£ã¦ã„ã‚‹å‹•ç”»** ã§ã™ã€‚  
> â±ï¸ **é•·ã•ã®ç›®å®‰**ï¼š**10ã€œ60ç§’/æœ¬** ã‚’ãŠã™ã™ã‚ã€**ä¸Šé™ã®ç›®å®‰ã¯ã€œ2åˆ†/æœ¬**ï¼ˆãã‚Œä»¥ä¸Šã¯ä½“æ„ŸãŒé‡ããªã‚Šã¾ã™ï¼‰ã€‚
""")

model_complexity = st.selectbox(
    "è§£æç²¾åº¦ã®è¨­å®š",
    options=[(0, "ä½ï¼ˆé«˜é€Ÿï¼‰"), (1, "ä¸­ï¼ˆãƒãƒ©ãƒ³ã‚¹ï¼‰"), (2, "é«˜ï¼ˆç²¾å¯†ï¼‰")],
    format_func=lambda x: x[1], index=1
)[0]

# æ‰‹å…¥åŠ›ãƒ»ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®çŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒ
st.session_state.setdefault("idx1", 0)
st.session_state.setdefault("idx2", 0)

with st.form("upload"):
    files = st.file_uploader("å‹•ç”»ã‚’2æœ¬é¸æŠï¼ˆé’â†’èµ¤ï¼‰", type=["mp4", "mov", "avi"], accept_multiple_files=True)
    submitted = st.form_submit_button("è§£æã‚’é–‹å§‹")

if submitted:
    if not files or len(files) < 2:
        st.warning("2æœ¬ã®å‹•ç”»ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
    else:
        paths, metas = [], []
        for f in files[:2]:
            # ä¸€æ™‚ä¿å­˜ â†’ æ­£è¦åŒ–
            temp = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(f.name)[1])
            temp.write(f.getvalue())
            temp.flush()
            norm = ffmpeg_normalize(temp.name)
            try:
                os.remove(temp.name)
            except Exception:
                pass
            paths.append(norm)
            metas.append(get_video_info(norm))
        st.session_state["paths"] = paths
        st.session_state["metas"] = metas
        # åˆæœŸä½ç½®ã‚’0ã«æˆ»ã™
        st.session_state.idx1 = 0
        st.session_state.idx2 = 0

if "paths" in st.session_state:
    p1, p2 = st.session_state["paths"]
    (t1, fps1, w1, h1), (t2, fps2, w2, h2) = st.session_state["metas"]

    st.subheader("ğŸ¬ éª¨æ ¼æ¯”è¼ƒï¼ˆã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ï¼‰")
    col1, col2 = st.columns(2)
    disp_w = st.slider("è¡¨ç¤ºã‚µã‚¤ã‚º(px)", 200, 900, 360, 10)

    # ä½“æ„Ÿã‚’è»½ãã™ã‚‹ãŸã‚ã€ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¯15fpsç›¸å½“ã§åˆ»ã‚€
    step1 = max(1, int((fps1 or 30) // 15))
    step2 = max(1, int((fps2 or 30) // 15))
    max1 = max(0, t1 - 1)
    max2 = max(0, t2 - 1)

    with col1:
        st.markdown("**é’å‹•ç”»**")
        # æ‰‹å…¥åŠ›ï¼ˆ1åˆ»ã¿ï¼‰
        num1 = st.number_input("ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ï¼ˆæ‰‹å…¥åŠ›ï¼‰", min_value=0, max_value=max1, value=int(st.session_state.idx1), step=1, key="num1_input")
        # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆè»½ã„åˆ»ã¿ï¼‰
        sld1 = st.slider("ãƒ•ãƒ¬ãƒ¼ãƒ ä½ç½®ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰", 0, max1, int(num1), step=step1, key="sld1")
        # æœ€çµ‚å€¤ã‚’çµ±ä¸€
        st.session_state.idx1 = int(sld1)

        f1 = read_frame(p1, st.session_state.idx1)
        lm1 = detect_landmarks(p1, st.session_state.idx1, model_complexity)
        if f1 is not None:
            draw_skeleton(f1, lm1, (255,0,0))
            st.image(f1, channels="BGR", width=disp_w)
            cap = f"ãƒ•ãƒ¬ãƒ¼ãƒ  {st.session_state.idx1+1}/{max(1,t1)}"
            if lm1 is None:
                cap += "ï¼ˆã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯æœªæ¤œå‡ºï¼‰"
            st.caption(cap)
        else:
            st.error("ãƒ•ãƒ¬ãƒ¼ãƒ ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    with col2:
        st.markdown("**èµ¤å‹•ç”»**")
        num2 = st.number_input("ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ï¼ˆæ‰‹å…¥åŠ›ï¼‰ ", min_value=0, max_value=max2, value=int(st.session_state.idx2), step=1, key="num2_input")
        sld2 = st.slider("ãƒ•ãƒ¬ãƒ¼ãƒ ä½ç½®ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰ ", 0, max2, int(num2), step=step2, key="sld2")
        st.session_state.idx2 = int(sld2)

        f2 = read_frame(p2, st.session_state.idx2)
        lm2 = detect_landmarks(p2, st.session_state.idx2, model_complexity)
        if f2 is not None:
            draw_skeleton(f2, lm2, (0,0,255))
            st.image(f2, channels="BGR", width=disp_w)
            cap = f"ãƒ•ãƒ¬ãƒ¼ãƒ  {st.session_state.idx2+1}/{max(1,t2)}"
            if lm2 is None:
                cap += "ï¼ˆã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯æœªæ¤œå‡ºï¼‰"
            st.caption(cap)
        else:
            st.error("ãƒ•ãƒ¬ãƒ¼ãƒ ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

else:
    st.info("2æœ¬ã®å‹•ç”»ã‚’é¸ã‚“ã§ã€è§£æã‚’é–‹å§‹ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
