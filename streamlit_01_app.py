import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import os

# --- MediaPipe Pose ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- éª¨æ ¼æç”» ---
def draw_skeleton_on_frame(frame, results_pose_landmarks, line_color=(255,0,0)):
    if results_pose_landmarks:
        spec = mp_drawing.DrawingSpec(color=line_color, thickness=2, circle_radius=2)
        mp_drawing.draw_landmarks(
            frame,
            results_pose_landmarks,
            mp_pose.POSE_CONNECTIONS,
            landmark_drawing_spec=spec,
            connection_drawing_spec=spec
        )
    return frame

# --- å‹•ç”»â†’ãƒ•ãƒ¬ãƒ¼ãƒ /éª¨æ ¼æŠ½å‡º ---
@st.cache_data(show_spinner=False)
def extract_frames_and_skeletons(uploaded_file, model_complexity=1, max_frame_height=640):
    if uploaded_file is None:
        return [], [], 0, 0, 0

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç’°å¢ƒä¾å­˜ã‚’é¿ã‘ã‚‹ï¼‰
    suffix = os.path.splitext(uploaded_file.name)[1] or ".mp4"
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.getbuffer())
        temp_file_path = tmp.name

    try:
        cap = cv2.VideoCapture(temp_file_path)
        if not cap.isOpened():
            return [], [], 0, 0, 0

        frames, landmarks_results = [], []
        ow = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 0
        oh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 0
        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0

        # ãƒªã‚µã‚¤ã‚ºè¨­å®š
        nw, nh = ow, oh
        if oh > max_frame_height and oh > 0:
            nh = max_frame_height
            nw = max(1, int(ow * (max_frame_height / oh)))

        # é€²æ—ãƒãƒ¼ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒå–ã‚Œãªã„å‹•ç”»ã‚‚ã‚ã‚‹ï¼‰
        if total > 0:
            bar = st.progress(0, text=f"å‡¦ç†ä¸­: {uploaded_file.name}")
        else:
            bar = None

        with mp_pose.Pose(
            static_image_mode=False,
            model_complexity=model_complexity,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:
            idx = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                if oh > max_frame_height and oh > 0:
                    frame = cv2.resize(frame, (nw, nh), interpolation=cv2.INTER_AREA)
                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image_rgb)
                frames.append(frame)
                landmarks_results.append(results.pose_landmarks)

                idx += 1
                if bar and total > 0:
                    bar.progress(min(100, int(idx / total * 100)), text=f"å‡¦ç†ä¸­: {uploaded_file.name} {min(100, int(idx / total * 100))}%")

        if bar:
            bar.empty()
        cap.release()
        return frames, landmarks_results, (nw or ow), (nh or oh), fps
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«æƒé™¤
        try:
            os.remove(temp_file_path)
        except Exception:
            pass

# --- UI ---
st.set_page_config(layout="wide", page_title="ãƒãƒ¬ã‚¨ãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒAI")
st.title("ãƒãƒ¬ã‚¨ãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒAI")

st.markdown("""
### ğŸ“– ä½¿ã„æ–¹
1. ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ **2ã¤ã®å‹•ç”»** ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆ1ã¤ç›®=é’éª¨æ ¼ã€2ã¤ç›®=èµ¤éª¨æ ¼ï¼‰ã€‚
2. èª­ã¿è¾¼ã¿å¾Œã€ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’ **æ‰‹å…¥åŠ›** ã¾ãŸã¯ **ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼** ã§é¸ã¶ã¨ã€åŒãƒ•ãƒ¬ãƒ¼ãƒ ã®éª¨æ ¼ãŒä¸¦ã‚“ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

âš ï¸ **æ³¨æ„**: é•·æ™‚é–“/é«˜è§£åƒåº¦ã®å‹•ç”»ã¯å‡¦ç†è½ã¡ã®åŸå› ã«ãªã‚Šã¾ã™ã€‚  
æ¨å¥¨: **30ç§’ä»¥å†…**ãƒ»**é«˜ã•æœ€å¤§640px** ç›¸å½“ã®è§£åƒåº¦
""")

uploaded_file1 = st.file_uploader("1ã¤ç›®ã®å‹•ç”»ï¼ˆé’éª¨æ ¼ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['mp4','mov','avi'], key="upload1")
uploaded_file2 = st.file_uploader("2ã¤ç›®ã®å‹•ç”»ï¼ˆèµ¤éª¨æ ¼ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['mp4','mov','avi'], key="upload2")

model_complexity = st.selectbox(
    "ãƒãƒ¼ã‚ºæ¨å®šãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦/é€Ÿåº¦",
    options=[(0,"ä½(é«˜é€Ÿ)"),(1,"ä¸­(ãƒãƒ©ãƒ³ã‚¹)"),(2,"é«˜(ä½é€Ÿ)")],
    index=1,
    format_func=lambda x: x[1]
)[0]

MAX_H = 640

# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
for i in [1,2]:
    st.session_state.setdefault(f'frames{i}', [])
    st.session_state.setdefault(f'landmarks{i}', [])
    st.session_state.setdefault(f'w{i}', 0)
    st.session_state.setdefault(f'h{i}', 0)
    st.session_state.setdefault(f'fps{i}', 0)
    st.session_state.setdefault(f'frame_index{i}', 0)

# å‹•ç”»å‡¦ç†ï¼ˆåŒåå†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®å†å‡¦ç†ã‚’é¿ã‘ã‚‹ã«ã¯åå‰ãƒã‚§ãƒƒã‚¯ç­‰ã‚’è¿½åŠ å¯èƒ½ï¼‰
if uploaded_file1:
    st.session_state.frames1, st.session_state.landmarks1, st.session_state.w1, st.session_state.h1, st.session_state.fps1 = extract_frames_and_skeletons(uploaded_file1, model_complexity, MAX_H)
    st.session_state.frame_index1 = 0
if uploaded_file2:
    st.session_state.frames2, st.session_state.landmarks2, st.session_state.w2, st.session_state.h2, st.session_state.fps2 = extract_frames_and_skeletons(uploaded_file2, model_complexity, MAX_H)
    st.session_state.frame_index2 = 0

# ãƒ•ãƒ¬ãƒ¼ãƒ æœ‰ç„¡ãƒã‚§ãƒƒã‚¯
if (uploaded_file1 and not st.session_state.frames1) or (uploaded_file2 and not st.session_state.frames2):
    st.error("å‹•ç”»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯/è§£åƒåº¦ã‚’ä¸‹ã’ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

# æ¯”è¼ƒUI
if st.session_state.frames1 and st.session_state.frames2:
    st.subheader("ãƒ•ãƒ¬ãƒ¼ãƒ é¸æŠã§éª¨æ ¼æ¯”è¼ƒ")
    # ç”»åƒå¹…ï¼ˆã‚¹ãƒãƒ›å¹…ã‚‚è€ƒæ…®ï¼‰
    default_width = 350 if st.session_state.w1 == 0 else min(350, st.session_state.w1)
    display_w = st.slider("è¡¨ç¤ºç”»åƒå¹…(px)", 120, 800, default_width, 10)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("1ã¤ç›®ã®å‹•ç”»ï¼ˆé’ï¼‰")
        max1 = len(st.session_state.frames1) - 1
        idx1 = st.number_input("ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ï¼ˆæ‰‹å…¥åŠ›ï¼‰", 0, max1, st.session_state.frame_index1, step=1, key="num1")
        idx1 = st.slider("ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰", 0, max1, idx1, step=1, key="sld1")
        st.session_state.frame_index1 = idx1

        frame1 = st.session_state.frames1[idx1].copy()
        draw_skeleton_on_frame(frame1, st.session_state.landmarks1[idx1], (255,0,0))
        st.image(frame1, channels="BGR", width=display_w)
        st.caption(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {idx1+1} / {max1+1}")

    with col2:
        st.subheader("2ã¤ç›®ã®å‹•ç”»ï¼ˆèµ¤ï¼‰")
        max2 = len(st.session_state.frames2) - 1
        idx2 = st.number_input("ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ï¼ˆæ‰‹å…¥åŠ›ï¼‰ ", 0, max2, st.session_state.frame_index2, step=1, key="num2")
        idx2 = st.slider("ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰ ", 0, max2, idx2, step=1, key="sld2")
        st.session_state.frame_index2 = idx2

        frame2 = st.session_state.frames2[idx2].copy()
        draw_skeleton_on_frame(frame2, st.session_state.landmarks2[idx2], (0,0,255))
        st.image(frame2, channels="BGR", width=display_w)
        st.caption(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {idx2+1} / {max2+1}")

elif uploaded_file1 or uploaded_file2:
    st.info("ä¸¡æ–¹ã®å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨æ¯”è¼ƒã§ãã¾ã™ã€‚")

