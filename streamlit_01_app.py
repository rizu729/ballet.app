import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import os

# --- MediaPipe Poseã®åˆæœŸåŒ– ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- éª¨æ ¼æç”»ç”¨é–¢æ•° ---
def draw_skeleton_on_frame(frame, results_pose_landmarks, line_color=(255,0,0)):
    if results_pose_landmarks:
        custom_drawing_spec = mp_drawing.DrawingSpec(color=line_color, thickness=2, circle_radius=2)
        custom_connection_spec = mp_drawing.DrawingSpec(color=line_color, thickness=2, circle_radius=2)
        mp_drawing.draw_landmarks(
            frame,
            results_pose_landmarks,
            mp_pose.POSE_CONNECTIONS,
            landmark_drawing_spec=custom_drawing_spec,
            connection_drawing_spec=custom_connection_spec
        )
    return frame

# --- å‹•ç”»å‡¦ç†é–¢æ•° ---
@st.cache_data(show_spinner=False)
def extract_frames_and_skeletons(uploaded_file, model_complexity=1, max_frame_height=640):
    if uploaded_file is None:
        return [], [], 0, 0, 0

    temp_dir = "/tmp"
    os.makedirs(temp_dir, exist_ok=True)
    temp_file_path = os.path.join(temp_dir, uploaded_file.name)
    
    try:
        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        cap = cv2.VideoCapture(temp_file_path)
        if not cap.isOpened():
            st.error(f"Error: Could not open video file: {uploaded_file.name}")
            return [], [], 0, 0, 0

        frames = []
        landmarks_results = []
        original_frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        original_frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))

        # ãƒªã‚µã‚¤ã‚ºè¨ˆç®—
        new_width = original_frame_width
        new_height = original_frame_height
        if original_frame_height > max_frame_height:
            new_height = max_frame_height
            new_width = int(original_frame_width * (max_frame_height / original_frame_height))
            if new_width == 0: new_width = 1

        progress_text = f"å‡¦ç†ä¸­: {uploaded_file.name} (é«˜ã•: {new_height}px)"
        my_bar = st.progress(0, text=progress_text)
        total_frames_in_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        with mp_pose.Pose(
            static_image_mode=False,
            model_complexity=model_complexity,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:

            frame_count = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                if original_frame_height > max_frame_height:
                    frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)

                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image_rgb)
                frames.append(frame)
                landmarks_results.append(results.pose_landmarks)

                frame_count += 1
                if total_frames_in_video > 0:
                    progress_percentage = min(100, int(frame_count / total_frames_in_video * 100))
                    my_bar.progress(progress_percentage, text=f"{progress_text} {progress_percentage}%")

        my_bar.empty()
        cap.release()
        st.success(f"å‹•ç”»å‡¦ç†å®Œäº†: {uploaded_file.name} (å…¨ {len(frames)} ãƒ•ãƒ¬ãƒ¼ãƒ )")
        return frames, landmarks_results, new_width, new_height, fps
    finally:
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)

# --- Streamlit UIè¨­å®š ---
st.set_page_config(layout="wide", page_title="ãƒãƒ¬ã‚¨ãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒAI")
st.title("ãƒãƒ¬ã‚¨ãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒAI")

# --- è©³ç´°ãªä½¿ã„æ–¹èª¬æ˜ ---
st.markdown("""
### ğŸ“– ä½¿ã„æ–¹

1. ä¸‹ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‹ã‚‰ã€æ¯”è¼ƒã—ãŸã„å‹•ç”»ã‚’ãã‚Œãã‚Œé¸æŠã—ã¦ãã ã•ã„ã€‚  
   - 1ã¤ç›®ã®å‹•ç”»ï¼šé’ã„éª¨æ ¼  
   - 2ã¤ç›®ã®å‹•ç”»ï¼šèµ¤ã„éª¨æ ¼  
   - å‹•ç”»ã¯çŸ­ã‚ï¼ˆæ¨å¥¨: 30ç§’ä»¥å†…ï¼‰ã€é«˜ã•æœ€å¤§640pxä»¥å†…ãŒæœ€é©ã§ã™ã€‚é•·ã„å‹•ç”»ã‚„é«˜è§£åƒåº¦å‹•ç”»ã¯å‡¦ç†ãŒé‡ããªã£ãŸã‚Šã€ã‚¢ãƒ—ãƒªãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹åŸå› ã«ãªã‚Šã¾ã™ã€‚

2. å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨è‡ªå‹•ã§éª¨æ ¼æ¨å®šãŒè¡Œã‚ã‚Œã¾ã™ã€‚å‡¦ç†ä¸­ã¯ã‚¢ãƒ—ãƒªãŒä¸€æ™‚åœæ­¢ã—ã¦è¦‹ãˆã¦ã‚‚ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§è¨ˆç®—ä¸­ã§ã™ã®ã§ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚

3. ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠã—ã¦æ¯”è¼ƒã§ãã¾ã™ã€‚  
   - æ‰‹å…¥åŠ›ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’ç›´æ¥å…¥åŠ›ï¼‰ã¾ãŸã¯ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§é¸æŠå¯èƒ½  
   - é¸æŠã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã®éª¨æ ¼ãŒæ¨ªä¸¦ã³ã§è¡¨ç¤ºã•ã‚Œã¾ã™

4. æ¯”è¼ƒã‚’è¦‹ãªãŒã‚‰ã€è‡ªåˆ†ã®å‹•ãã¨ç†æƒ³ã®å‹•ãã®é•ã„ã‚’ç¢ºèªã—ã¦ãƒ•ã‚©ãƒ¼ãƒ æ”¹å–„ã«å½¹ç«‹ã¦ã¦ãã ã•ã„ã€‚
""")

# --- å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_file1 = st.file_uploader("1ã¤ç›®ã®å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆé’éª¨æ ¼ï¼‰", type=['mp4','mov','avi'])
uploaded_file2 = st.file_uploader("2ã¤ç›®ã®å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆèµ¤éª¨æ ¼ï¼‰", type=['mp4','mov','avi'])

# ãƒ¢ãƒ‡ãƒ«è¤‡é›‘ã•é¸æŠ
model_complexity_option = st.selectbox(
    "ãƒãƒ¼ã‚ºæ¨å®šãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦/é€Ÿåº¦",
    options=[(0,"ä½(é«˜é€Ÿ)"),(1,"ä¸­(ãƒãƒ©ãƒ³ã‚¹)"),(2,"é«˜(ä½é€Ÿ)")],
    format_func=lambda x: x[1],
    index=1
)[0]

MAX_FRAME_HEIGHT = 640

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ ---
for i in [1,2]:
    if f'frames{i}' not in st.session_state:
        st.session_state[f'frames{i}'] = []
        st.session_state[f'landmarks{i}'] = []
        st.session_state[f'w{i}'], st.session_state[f'h{i}'], st.session_state[f'fps{i}'] = 0,0,0
        st.session_state[f'frame_index{i}'] = 0

# --- å‹•ç”»å‡¦ç† ---
if uploaded_file1 and (not st.session_state.frames1 or uploaded_file1.name != st.session_state.get('uploaded_file1_name')):
    with st.spinner("1ã¤ç›®ã®å‹•ç”»ã‚’å‡¦ç†ä¸­..."):
        st.session_state.frames1, st.session_state.landmarks1, st.session_state.w1, st.session_state.h1, st.session_state.fps1 = extract_frames_and_skeletons(uploaded_file1, model_complexity=model_complexity_option, max_frame_height=MAX_FRAME_HEIGHT)
    st.session_state.uploaded_file1_name = uploaded_file1.name

if uploaded_file2 and (not st.session_state.frames2 or uploaded_file2.name != st.session_state.get('uploaded_file2_name')):
    with st.spinner("2ã¤ç›®ã®å‹•ç”»ã‚’å‡¦ç†ä¸­..."):
        st.session_state.frames2, st.session_state.landmarks2, st.session_state.w2, st.session_state.h2, st.session_state.fps2 = extract_frames_and_skeletons(uploaded_file2, model_complexity=model_complexity_option, max_frame_height=MAX_FRAME_HEIGHT)
    st.session_state.uploaded_file2_name = uploaded_file2.name

# --- ãƒ•ãƒ¬ãƒ¼ãƒ æ¯”è¼ƒ ---
if st.session_state.frames1 and st.session_state.frames2:
    st.subheader("ãƒ•ãƒ¬ãƒ¼ãƒ é¸æŠã§éª¨æ ¼æ¯”è¼ƒ")
    display_image_width = st.slider("è¡¨ç¤ºç”»åƒå¹…ã‚’èª¿æ•´ (px)", 100, 800, min(350, st.session_state.w1), 10)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("1ã¤ç›®ã®å‹•ç”» (é’)")
        st.session_state.frame_index1 = st.number_input(
            "ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’å…¥åŠ›",
            min_value=0,
            max_value=len(st.session_state.frames1)-1,
            value=st.session_state.frame_index1,
            step=1,
            key="input1"
        )
        st.session_state.frame_index1 = st.slider(
            "ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼",
            min_value=0,
            max_value=len(st.session_state.frames1)-1,
            value=st.session_state.frame_index1,
            step=1,
            key="slider1"
        )
        current_frame1 = st.session_state.frames1[st.session_state.frame_index1].copy()
        draw_skeleton_on_frame(current_frame1, st.session_state.landmarks1[st.session_state.frame_index1], line_color=(255,0,0))
        st.image(current_frame1, channels="BGR", caption=f"1ã¤ç›®ã®å‹•ç”» - ãƒ•ãƒ¬ãƒ¼ãƒ  {st.session_state.frame_index1}", width=display_image_width)

    with col2:
        st.subheader("2ã¤ç›®ã®å‹•ç”» (èµ¤)")
        st.session_state.frame_index2 = st.number_input(
            "ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’å…¥åŠ›",
            min_value=0,
            max_value=len(st.session_state.frames2)-1,
            value=st.session_state.frame_index2,
            step=1,
            key="input2"
        )
        st.session_state.frame_index2 = st.slider(
            "ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼",
            min_value=0,
            max_value=len(st.session_state.frames2)-1,
            value=st.session_state.frame_index2,
            step=1,
            key="slider2"
        )
        current_frame2 = st.session_state.frames2[st.session_state.frame_index2].copy()
        draw_skeleton_on_frame(current_frame2, st.session_state.landmarks2[st.session_state.frame_index2], line_color=(0,0,255))
        st.image(current_frame2, channels="BGR", caption=f"2ã¤ç›®ã®å‹•ç”» - ãƒ•ãƒ¬ãƒ¼ãƒ  {st.session_state.frame_index2}", width=display_image_width)
